{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew,norm\n",
    "from tqdm import tqdm  \n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=pd.read_csv('../datasets/tianchi/health/origin_data/meinian_round1_train_20180408.csv',\n",
    "              engine='python',encoding=\"gbk\")\n",
    "Y_pred=pd.read_csv('../datasets/tianchi/health/b_round/meinian_round1_test_b_20180505.csv',\n",
    "                   engine='python',encoding=\"gbk\")\n",
    "\n",
    "Y.columns=[\"vid\",\"Systolic\",'Diastolic','Glycerin','HDC','LDC']\n",
    "Y_pred.columns=[\"vid\",\"Systolic\",'Diastolic','Glycerin','HDC','LDC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 我们发现Y的前三项数据由于存在字符无法转成数值型数据、用正则表达式提取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_test=Y_pred.shape[0]\n",
    "m_train=Y.shape[0]\n",
    "columns=['Systolic','Diastolic','Glycerin']\n",
    "for col in columns:\n",
    "    temp=[]\n",
    "    for i in range(m_train):\n",
    "        pattern = re.compile(r'\\d+\\.{0,1}\\d+')   ##数值中间最多允许出现一个小数点\n",
    "        try:\n",
    "            temp.append(pattern.findall(Y[col][i])[0])\n",
    "        except:\n",
    "            temp.append(np.nan)\n",
    "    Y[col]=temp\n",
    "    Y[col]=Y[col].astype(\"float32\")\n",
    "    Y[col]=Y[col].fillna(Y[col].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distplot Y的列，我们可以发现Diastolic有两个异常,并且HDC有负值(取绝对值处理),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=Y[Y[\"Diastolic\"]<200]        ## 删除异常值\n",
    "Y[\"LDC\"]=np.abs(Y[\"LDC\"])      ## 将负值取绝对值\n",
    "Y=Y.set_index(\"vid\")\n",
    "Y_pred=Y_pred.set_index(\"vid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入X  并生成数据透视表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X=[]\n",
    "# with open(\"../datasets/tianchi/health/origin_data/meinian_round1_data_part1_20180408.txt\",\"r\") as f:\n",
    "#     for line in f.readlines():\n",
    "#         x=line.strip().split(\"$\")\n",
    "#         X.append(x)\n",
    "\n",
    "# X1=pd.DataFrame(X[1:],columns=[\"vid\",\"table_id\",\"field_results\"])\n",
    "\n",
    "# X=[]\n",
    "# with open(\"../datasets/tianchi/health/origin_data/meinian_round1_data_part2_20180408.txt\",\"r\") as f:\n",
    "#     for line in f.readlines():\n",
    "#         x=line.strip().split(\"$\")\n",
    "#         X.append(x)\n",
    "# X2=pd.DataFrame(X[1:],columns=[\"vid\",\"table_id\",\"field_results\"])\n",
    "\n",
    "# X=pd.concat([X1,X2],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1_train=pd.pivot_table(X,index='vid',\n",
    "#                        columns='table_id', \n",
    "#                        values='field_results',\n",
    "#                        fill_value=np.nan,\n",
    "#                        aggfunc=lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 只提取train和test中有的数据并将其合并,一起进行数值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_list=Y[\"vid\"].values\n",
    "# X_train=X1_train.loc[train_list]\n",
    "\n",
    "# ###this is data for prediction\n",
    "# test_list=Y_pred[\"vid\"].values\n",
    "# X_test=X1_train.loc[test_list]\n",
    "\n",
    "# # X_train.to_csv('../datasets/tianchi/health/train.csv',index=True)\n",
    "# # X_test.to_csv('../datasets/tianchi/health/test.csv',index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-d53337fe5075>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../datasets/tianchi/health/train.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../datasets/tianchi/health/test.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mm_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mm_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1067\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'as_recarray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1837\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1839\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1840\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_integer_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m     \"\"\"\n\u001b[1;32m    779\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train=pd.read_csv('../datasets/tianchi/health/train.csv',low_memory=False)\n",
    "X_test=pd.read_csv('../datasets/tianchi/health/test.csv',low_memory=False)\n",
    "m_train=X_train.shape[0]\n",
    "m_test=X_test.shape[0]\n",
    "\n",
    "all_data=pd.concat([X_train,X_test],axis=0)\n",
    "print(\"The shape of all data is {}\".format(all_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 删除缺失值超过97%的feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_drop=all_data.isnull().sum().sort_values(ascending=False)/len(all_data)*100\n",
    "to_drop=to_drop[to_drop>97.0]\n",
    "all_data.drop(to_drop.index,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根据其他项信息提取性别Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender=[]\n",
    "all_data[\"0101\"]=all_data[\"0101\"].astype(str)\n",
    "all_data[\"0102\"]=all_data[\"0102\"].astype(str)\n",
    "all_data[\"0539\"]=all_data[\"0539\"].astype(str)\n",
    "all_data[\"0120\"]=all_data[\"0120\"].astype(str)\n",
    "all_data[\"0121\"]=all_data[\"0121\"].astype(str)\n",
    "all_data[\"0929\"]=all_data[\"0929\"].astype(str)\n",
    "for i in range(all_data.shape[0]):\n",
    "\n",
    "    if \"乳腺\" in all_data[\"0101\"].values[i]:\n",
    "        gender.append(\"F\")\n",
    "    elif \"乳房\" in all_data[\"0101\"].values[i]:\n",
    "        gender.append(\"F\")\n",
    "    elif \"乳腺\" in all_data[\"0102\"].values[i]:\n",
    "        gender.append(\"F\")\n",
    "    elif \"子宫\" in all_data[\"0102\"].values[i]:\n",
    "        gender.append(\"F\")\n",
    "    elif \"乳腺\" in all_data[\"0121\"].values[i]:\n",
    "        gender.append(\"F\")\n",
    "    elif \"子宫\" in all_data[\"0121\"].values[i]:\n",
    "        gender.append(\"F\")\n",
    "    elif \"阴道\" in all_data[\"0539\"].values[i]:\n",
    "        gender.append(\"F\")\n",
    "    elif \"妇科\" in all_data[\"0539\"].values[i]:\n",
    "        gender.append(\"F\")\n",
    "    elif \"宫颈\" in all_data[\"0539\"].values[i]:\n",
    "        gender.append(\"F\")\n",
    "    elif \"乳腺\" in all_data[\"0929\"].values[i]:\n",
    "        gender.append(\"F\")\n",
    "    elif \"小叶增生\" in all_data[\"0929\"].values[i]:\n",
    "        gender.append(\"F\")\n",
    "    elif \"前列腺\" in all_data[\"0102\"].values[i]:\n",
    "        gender.append(\"M\")\n",
    "    elif \"前列腺\" in all_data[\"0120\"].values[i]:\n",
    "        gender.append(\"M\")\n",
    "    else:\n",
    "        gender.append(\"unkown\")\n",
    "all_data[\"gender\"]=gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47735/47735 [00:03<00:00, 14233.28it/s]\n"
     ]
    }
   ],
   "source": [
    "age=[]\n",
    "all_data[\"3601\"]=all_data[\"3601\"].astype(str)\n",
    "all_data[\"0102\"]=all_data[\"0102\"].astype(str)\n",
    "all_data[\"0709\"]=all_data[\"0709\"].astype(str)\n",
    "all_data[\"0730\"]=all_data[\"0730\"].astype(str)\n",
    "all_data[\"0120\"]=all_data[\"0120\"].astype(str)\n",
    "all_data[\"A202\"]=all_data[\"A202\"].astype(str)\n",
    "all_data[\"0409\"]=all_data[\"0409\"].astype(str)\n",
    "all_data[\"1102\"]=all_data[\"1102\"].astype(str)\n",
    "all_data[\"1103\"]=all_data[\"1103\"].astype(str)\n",
    "all_data[\"1308\"]=all_data[\"1308\"].astype(str)\n",
    "all_data[\"0546\"]=all_data[\"0546\"].astype(str)\n",
    "all_data[\"0984\"]=all_data[\"0984\"].astype(str)\n",
    "for i in tqdm(range(all_data.shape[0])):\n",
    "\n",
    "    if \"骨质增生\" in all_data[\"1102\"].values[i]:  ###骨质增生与疏松\n",
    "        age.append(\"old\")\n",
    "    elif \"退行性变\" in all_data[\"1102\"].values[i]:\n",
    "        age.append(\"old\")\n",
    "    elif \"骨质增生\" in all_data[\"1103\"].values[i]:\n",
    "        age.append(\"old\")\n",
    "    elif \"骨质疏松\" in all_data[\"3601\"].values[i]:\n",
    "        age.append(\"old\")\n",
    "    elif \"减少\" in all_data[\"3601\"].values[i]:\n",
    "        age.append(\"old\")\n",
    "    elif \"骨密度降低\" in all_data[\"3601\"].values[i]:\n",
    "        age.append(\"old\")\n",
    "    elif \"绝经\" in all_data[\"0546\"].values[i]:    ###绝经情况\n",
    "        age.append(\"old\")\n",
    "    elif \"闭经\" in all_data[\"0546\"].values[i]:\n",
    "        age.append(\"old\")\n",
    "    elif \"停经\" in all_data[\"0546\"].values[i]:\n",
    "        age.append(\"old\")\n",
    "    elif \"绝经\" in all_data[\"0102\"].values[i]:\n",
    "        age.append(\"old\")\n",
    "    elif \"高血压\" in all_data[\"0409\"].values[i]:   ####三高病史\n",
    "        age.append(\"old\")\n",
    "    elif \"糖尿病\" in all_data[\"0409\"].values[i]:\n",
    "        age.append(\"old\")\n",
    "    elif \"冠心病\" in all_data[\"0409\"].values[i]:\n",
    "        age.append(\"old\")\n",
    "        \n",
    "    elif \"增大\" in all_data[\"0120\"].values[i]:   ###前列腺增大\n",
    "        age.append(\"old\")\n",
    "    elif \"义齿\" in all_data[\"0709\"].values[i]:   ###是否有义齿\n",
    "        age.append(\"old\")\n",
    "        \n",
    "    elif \"老年环\" in all_data[\"1308\"].values[i]:   ###老年眼科病\n",
    "        age.append(\"old\")\n",
    "    elif \"白内障\" in all_data[\"1308\"].values[i]:   \n",
    "        age.append(\"old\")\n",
    "    elif \"玻璃体浑浊\" in all_data[\"1308\"].values[i]:   \n",
    "        age.append(\"old\")\n",
    "    elif \"增生\" in all_data[\"0984\"].values[i]:   \n",
    "        age.append(\"old\")\n",
    "    elif \"lmp\" in all_data[\"0546\"].values[i].lower():\n",
    "        age.append(\"young\")\n",
    "    elif \"月经\" in all_data[\"0546\"].values[i]:\n",
    "        age.append(\"young\")\n",
    "    elif \"哺乳\" in all_data[\"0546\"].values[i]:\n",
    "        age.append(\"young\")\n",
    "    else:\n",
    "        age.append(\"unknown\")\n",
    "all_data[\"age\"]=age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"num_items\"]=all_data.isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 431/431 [00:47<00:00,  9.09it/s]\n"
     ]
    }
   ],
   "source": [
    "##将正常数据（表达不同），均映射为形同的值\n",
    "#X['field_results'].value_counts().sort_values(ascending=False)[:50]\n",
    "all_data=all_data.astype(str)\n",
    "for col in tqdm(all_data.columns):\n",
    "    all_data[col]=all_data[col].replace({\"弃查\":np.nan,           ## 将result数据做基本处理.相同意义的数据替换\n",
    "                                         \"正常 正常\":'正常',\n",
    "                                         \"未见异常 未见异常\":'正常',\n",
    "                                         \"未触及 未触及\":\"正常\",\n",
    "                                             \"未见异常\":\"正常\",\n",
    "                                             \"未见明显异常\":\"正常\",\n",
    "                                            \"未见异常，活动自如\":\"正常\",\n",
    "                                            \"健康\":\"正常\",\n",
    "                                            \"整齐\":\"正常\",\n",
    "                                            \"详见纸质报告\":np.nan,\n",
    "                                            \"未查\":np.nan,\n",
    "                                            \"未触及\":\"正常\",\n",
    "                                            \"正常心电图\":\"正常\",\n",
    "                                             \"窦性心律正常心电图 \":\"正常\",\n",
    "                                            \"骨量正常\":\"正常\",\n",
    "                                            \"耳鼻喉检查未见异常\":\"正常\",\n",
    "                                            \"外科检查未发现明显异常\":\"正常\",\n",
    "                                            \"内科检查未发现明显异常\":\"正常\",\n",
    "                                            \"右附件区未见明显异常回声\":\"正常\",\n",
    "                                            \"胰腺大小、形态正常，边缘规整，内部回声均匀，胰管未见扩张。\":\"正常\",\n",
    "                                            \"右肾大小、形态正常，包膜光滑，肾实质回声均匀，集合系统未见明显分离。\":\"正常\",\n",
    "                                            \"左肾大小、形态正常，包膜光滑，肾实质回声均匀，集合系统未见明显分离。\":\"正常\",\n",
    "                                            \"胆囊大小、形态正常，囊壁光整，囊腔内透声好，胆总管无扩张。\":\"正常\",\n",
    "                                            \"膀胱充盈良好，壁光滑，延续性好，其内透声性良好，未见明显占位性病变。\":\"正常\",\n",
    "                                            \"脾脏大小、形态正常，包膜光整，回声均匀。\":\"正常\",\n",
    "                                            \"脾脏大小、形态正常，包膜光整，内光点均匀。\":\"正常\",\n",
    "                                            \"右附件区未见明显异常回声。\":\"正常\",\n",
    "                                            \"左附件区未见明显异常回声。\":\"正常\",\n",
    "                                            \"肝、胆、胰、脾、左肾、右肾未发现明显异常\":\"正常\",\n",
    "                                            \"肝脏大小、形态正常，包膜光整，肝内血管走行较清晰，回声均匀。\":\"正常\",\n",
    "                                            \"前列腺大小、形态正常，包膜光滑完整，两侧对称，内部回声均匀。\":\"正常\",\n",
    "                                            \"甲状腺形态大小正常，边界清晰，内部回声分布均匀，未见明显异常回声。\":\"正常\",\n",
    "                                            \"双侧甲状腺大小形态正常，包膜光整，实质回声均匀，未见明显异常回声。CDFI：血流显示未见异常。\":\"正常\",\n",
    "                                            \"胸廓对称，双肺纹理清晰，走行自然，未见异常实变影，双肺门不大。纵隔窗示纵隔无偏移，心影及大血管形态正常，纵隔内未见肿块及肿大淋巴结。胸腔内未见积液。\":\"正常\",\n",
    "                                            \"脾脏大小测值正常，回声均匀，脾静脉测值正常。\":\"正常\",\n",
    "                                            \"甲状腺彩超未发现明显异常\":\"正常\",\n",
    "                                            \"肝脏大小、形态正常，包膜光整，肝内血管走行较清晰，光点分布尚均匀，其内未见明显异常光团。\":\"正常\",\n",
    "                                            \"无特殊记载\":\"正常\",\n",
    "                                            \"胰腺头、体、尾大小测值正常，内回声均匀。\":\"正常\",\n",
    "                                            \"前列腺未发现明显异常\":\"正常\",\n",
    "                                            \"双侧颈总动脉管径对称，内中膜不增厚,血流速度正常。双侧颈总动脉分叉处管径对称，内中膜不增厚，血流速度正常。双侧颈内、外动脉管径对称，管壁回声正常，血流速度正常。\":\"正常\",\n",
    "                                            \"回声正常，血流速度正常。\":\"正常\",\n",
    "                                            \"胆囊大小正常，壁光滑，腔内暗区清晰，胆总管测值正常范围。\":\"正常\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv(\"../datasets/tianchi/health/v9/all_data_pivot-v9.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature enginering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47735, 431)\n"
     ]
    }
   ],
   "source": [
    "all_data=pd.read_csv(\"../datasets/tianchi/health/v9/all_data_pivot-v9.csv\",low_memory=False)\n",
    "print(all_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取 numeric feature\n",
    "以下用mean填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:54<00:00,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "columns=[\"0424\",\"10004\",\"1117\",\"1321\",\"1322\",\"190\",\"191\",\"192\",\"2403\",\"2404\",\"2405\",\"316\",\"320\",\n",
    "         \"1814\",\"1815\",\"1840\",\"1850\",\"2372\",\"31\",\"32\",\"33\",\"34\",\"38\",\"39\",\"37\",\"312\",\"313\",\"315\",\n",
    "         \"2406\",\"1127\",\"155\",\"269003\",\"269004\",\"269005\",\"269006\",\"269008\",\"269009\",\"269010\",\n",
    "        \"269012\",\"269013\",\"269014\",\"269015\",\"269016\",\"269017\",\"269018\",\"269019\",\"269020\",\"269021\",\n",
    "        \"269022\",\"269023\",\"269024\",\"269025\",\"1845\"]\n",
    "\n",
    "for col in tqdm(columns):\n",
    "    all_data[col]=all_data[col].astype(str)\n",
    "    temp=[]\n",
    "    for i in range(len(all_data)):\n",
    "        pattern = re.compile(r'\\d+\\.{0,1}\\d+')\n",
    "        try:\n",
    "            temp.append(pattern.findall(all_data[col][i])[0])\n",
    "        except:\n",
    "            temp.append(np.nan)\n",
    "    all_data[col]=temp\n",
    "    all_data[col]=all_data[col].astype(\"float32\")\n",
    "    all_data[col]=all_data.groupby([\"gender\",\"age\"])[col].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 179/179 [02:45<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "columns1=[\"0424\",\"10004\",\"1117\",\"1321\",\"1322\",'459161', '809035', '459156', '319100', '0111', '809016',\n",
    "         \"2410\",\"2165\",\"2411\",\"2421\",\"2413\",\"10013\",\"2168\",\"1842\",\"2412\",\"300028\",\"300048\",\"300113\",\"709001\",\n",
    "         \"100008\",\"300044\",\"0104\",\"300067\",\"300125\",\"0107\",\"300009\",\"300014\",\"809003\",\n",
    "         '459155', '0105', '459158', '0106', '300006', '311', '3184', '35', '300129', '0109', '310', \n",
    "         \"1814\",\"1815\",\"183\",\"1840\",\"1850\",\"31\",\"32\",\"33\",\"34\",\"38\",\"39\",\"37\",\"312\",'809030', '36',\n",
    "         \"313\",\"315\",\"316\",\"320\",\"190\",\"191\",\"192\",\"2403\",\"2404\",\"2405\",'300069', '459159', '0108', '1124',\n",
    "         \"2406\",\"1127\",\"155\",\"269003\",\"269004\",\"269005\",\"269006\",\"269008\",\"269009\",\"269010\", '459154',\n",
    "        \"269012\",\"269013\",\"269014\",\"269015\",\"269016\",\"269017\",\"269018\",\"269019\",\"269020\",\"269021\",\n",
    "        \"269022\",\"269023\",\"269024\",\"269025\",\"100012\",\"100013\",\"100014\",\"10009\",\"1106\",\"1107\",\"1112\",\"1325\",\n",
    "        \"1326\",\"139\",\"143\",\"1474\",\"2386\",\"2409\",\"269007\",\"300001\",\"300008\",\"300011\",\"300012\",\"300013\",\n",
    "        \"300021\",\"300092\",\"669001\",\"669002\",\"669004\",\"669005\",\"669006\",\"669009\",\"669021\",\"809001\",\n",
    "        \"809004\",\"809008\",\"809009\",\"809010\",\"809013\",\"809017\",\"809021\",\"809023\",\"809025\",\"809026\",\"979001\",\"979002\",\n",
    "        \"979003\",\"979004\",\"979005\",\"979006\",\"979007\",\"979008\",\"979009\",\"004997\",\"1110\",\"1319\",\"1320\",\"1844\",\"1873\",\n",
    "        \"189\",\"20002\",\"279006\",\"300007\",\"300068\",\"300070\",\"300074\",\"300076\",\"669003\",\"669007\",\"669008\",\n",
    "        \"809013\",\"809018\",\"809019\",\"809022\",\"809027\",\"1125\",\"1331\",\"1845\",\"979011\",\"979012\",\n",
    "        \"2390\",\"2407\",\"2986\",\"300035\",\"30006\",\"300078\",\"321\",\"809002\",\"809007\",\"809020\",\"809024\",\"809029\",\n",
    "        \"809031\",\"809032\",\"809033\",\"809034\",\"979010\",\"979025\",\"979026\",\"979027\",\"A701\",\"A703\",\n",
    "        ]+[str(i) for i in range(979013,979024,1)]+[str(i) for i in range(809037,809062,1)]\n",
    "for col in tqdm(set(columns1)-set(columns)):\n",
    "    all_data[col]=all_data[col].astype(str)\n",
    "    temp=[]\n",
    "    for i in range(len(all_data)):\n",
    "        pattern = re.compile(r'\\d+\\.{0,1}\\d+')\n",
    "        try:\n",
    "            temp.append(pattern.findall(all_data[col][i])[0])\n",
    "        except:\n",
    "            temp.append(np.nan)\n",
    "    all_data[col]=temp\n",
    "    all_data[col]=all_data[col].astype(\"float32\")\n",
    "    all_data[col]=all_data[col].fillna(all_data[col].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下数据用0填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:02<00:00,  5.94it/s]\n"
     ]
    }
   ],
   "source": [
    "columns=[\"300005\",\"3429\",\"3193\",\"3730\",\"2177\",\"2376\",\"300017\",\"300018\",\"300019\",\"979024\",\"269026\",\n",
    "         \"669024\",\"2371\",\"300036\",\"1363\"]\n",
    "for col in tqdm(columns):\n",
    "    all_data[col]=all_data[col].astype(str)\n",
    "    all_data[col].fillna(\"None\",inplace=True)\n",
    "    temp=[]\n",
    "    for i,j in enumerate(all_data[col].values):\n",
    "        \n",
    "        if \"+\" in j or \"阳性\" in j:\n",
    "            if col==\"3730\" or col==\"300019\" or col==\"2371\":\n",
    "                temp.append(5)\n",
    "            elif col==\"669004\":\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(40)\n",
    "        elif \"-\" in j or \"阴性\" in j:\n",
    "            temp.append(0)\n",
    "        else:\n",
    "            pattern = re.compile(r'\\d+\\.{0,1}\\d+')\n",
    "            try:\n",
    "                temp.append(pattern.findall(j)[0])\n",
    "            except:\n",
    "                temp.append(np.nan)\n",
    "    all_data[col]=temp\n",
    "    all_data[col]=all_data[col].astype(\"float32\")\n",
    "    all_data[col]=all_data[col].fillna(all_data[col].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###夹杂着阳性数据的单独处理，阳性按照较大值处理,缺失值按照阴性0处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据后面模型的feature_importance，下面的数据，importance高，但缺失值非常多，我们着重处理   \n",
    "严重：“193”，“10002”，“0425”，“319”，“2372”，“314”，“100007”，“2174”，“1115”，“2333”，“317”，“10003”，“100006”，“183”  \n",
    "非常严重：”100005“，“269011”，“2420”，”1345“，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:16<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "columns=[\"193\",\"10002\",\"0425\",\"319\",\"2372\",\"314\",\"100007\",\"2174\",\"1115\",\"2333\",\"317\",\"10003\",\n",
    "         \"100006\",\"183\",\"100005\",\"269011\",\"2420\",\"1345\"]\n",
    "for col in tqdm(columns):\n",
    "    all_data[col]=all_data[col].astype(str)\n",
    "    temp=[]\n",
    "    for i in range(len(all_data)):\n",
    "        pattern = re.compile(r'\\d+\\.{0,1}\\d+')\n",
    "        try:\n",
    "            temp.append(pattern.findall(all_data[col][i])[0])\n",
    "        except:\n",
    "            temp.append(np.nan)\n",
    "    all_data[col]=temp\n",
    "    all_data[col]=all_data[col].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ###all_data.corr()[\"1345\"].sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"193\"]=all_data.groupby(all_data[\"192\"]>all_data[\"192\"].mean()\n",
    "                                )[\"193\"].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "all_data[\"10002\"]=all_data.groupby(all_data[\"192\"]>all_data[\"192\"].mean()\n",
    "                                )[\"10002\"].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "all_data[\"0425\"]=all_data.groupby(all_data[\"0424\"]>all_data[\"0424\"].mean()\n",
    "                                )[\"0425\"].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "all_data[\"319\"]=all_data.groupby(all_data[\"312\"]>all_data[\"312\"].mean()\n",
    "                                )[\"319\"].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "###没有相关性较好的数据，直接用平均值填充\n",
    "all_data[\"2372\"]=all_data[\"2372\"].fillna(all_data[\"2372\"].mean())\n",
    "\n",
    "all_data[\"314\"]=all_data.groupby(all_data[\"37\"]>all_data[\"37\"].mean()\n",
    "                                )[\"314\"].transform(lambda x: x.fillna(x.mean()))\n",
    "all_data[\"100007\"]=all_data[\"100007\"].fillna(all_data[\"100007\"].mean())\n",
    "\n",
    "all_data[\"2174\"]=all_data.groupby(all_data[\"1845\"]>all_data[\"1845\"].mean()\n",
    "                                )[\"2174\"].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "all_data[\"1115\"]=all_data.groupby(all_data[\"1117\"]>all_data[\"1117\"].median()\n",
    "                                )[\"1115\"].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "all_data[\"2333\"]=all_data[\"2333\"].fillna(all_data[\"2333\"].mean())\n",
    "\n",
    "all_data[\"317\"]=all_data.groupby(all_data[\"316\"]>all_data[\"316\"].mean()\n",
    "                                )[\"317\"].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "all_data[\"10003\"]=all_data.groupby(all_data[\"183\"]>all_data[\"183\"].mean()\n",
    "                                )[\"10003\"].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "all_data[\"100006\"]=all_data[\"100006\"].fillna(all_data[\"100006\"].mean())\n",
    "\n",
    "all_data[\"100005\"]=all_data.groupby(all_data[\"320\"]>all_data[\"320\"].mean()\n",
    "                                )[\"100005\"].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "all_data[\"183\"]=all_data.groupby(all_data[\"10003\"]>all_data[\"10003\"].mean()\n",
    "                                )[\"183\"].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "all_data[\"269011\"]=all_data.groupby(all_data[\"38\"]>all_data[\"38\"].mean()\n",
    "                                )[\"269011\"].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "all_data[\"2420\"]=all_data.groupby(all_data[\"0424\"]>all_data[\"0424\"].mean()\n",
    "                                )[\"2420\"].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "all_data[\"1345\"]=all_data.groupby(all_data[\"100012\"]>all_data[\"100012\"].mean()\n",
    "                                )[\"1345\"].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 找出现相关性最高的group后进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv(\"../datasets/tianchi/health/v9/all_data_pivot_numeric_done-v9.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=pd.read_csv(\"../datasets/tianchi/health/v9/all_data_pivot_numeric_done-v9.csv\",low_memory=False)\n",
    "# ##all_data[all_data.dtypes[all_data.dtypes !=\"object\"].index].isnull().sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=all_data.set_index(\"vid\")\n",
    "X_train=all_data[:-m_test]\n",
    "X_test=all_data[-m_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([X_train,Y],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.scatter(df[\"459154\"],df[\"Systolic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 其实也可以用方差，均值方法，提出异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#all_data.dtypes[all_data.dtypes !=\"object\"].index\n",
    "df=df[df[\"0104\"]<100]\n",
    "df=df[df[\"100008\"]<10]\n",
    "df=df[df[\"709001\"]<1]\n",
    "df=df[df[\"2412\"]<100]\n",
    "df=df[df[\"1842\"]<100]\n",
    "df=df[df[\"10013\"]<400]\n",
    "df=df[df[\"2411\"]<1000]\n",
    "df=df[df[\"1363\"]<250]\n",
    "df=df[df[\"2410\"]<60]\n",
    "df=df[df[\"A701\"]<100]\n",
    "df=df[df[\"809031\"]<100]\n",
    "df=df[df[\"300035\"]<80]\n",
    "df=df[df[\"2986\"]<100]\n",
    "df=df[df[\"2407\"]<4000]\n",
    "df=df[df[\"1331\"]<4]\n",
    "df=df[df[\"669008\"]<100]\n",
    "df=df[df[\"300076\"]<100]\n",
    "df=df[df[\"300074\"]<20]\n",
    "df=df[df[\"300070\"]<15]\n",
    "df=df[df[\"300068\"]<50]\n",
    "df=df[df[\"1873\"]<40]\n",
    "df=df[df[\"1844\"]<4]\n",
    "df=df[df[\"1110\"]<50]\n",
    "df=df[df[\"979014\"]<2.0]\n",
    "df=df[df[\"979002\"]<1.5]\n",
    "df=df[df[\"809025\"]<15]\n",
    "df=df[df[\"809009\"]<15]\n",
    "df=df[df[\"669021\"]<100]\n",
    "df=df[df[\"669006\"]<60]\n",
    "df=df[df[\"669004\"]<40]\n",
    "df=df[df[\"669002\"]<15]\n",
    "df=df[df[\"669001\"]<40]\n",
    "df=df[df[\"300017\"]<20]\n",
    "df=df[df[\"300012\"]<20]\n",
    "df=df[df[\"300008\"]<4]\n",
    "df=df[df[\"300001\"]<60]\n",
    "df=df[df[\"2376\"]<800]\n",
    "df=df[df[\"2177\"]<200]\n",
    "df=df[df[\"1474\"]<300]\n",
    "df=df[df[\"139\"]<6]\n",
    "df=df[df[\"1112\"]<20]\n",
    "df=df[df[\"10009\"]<60]\n",
    "df=df[df[\"100014\"]<60]\n",
    "df=df[df[\"100013\"]<12]\n",
    "df=df[df[\"269023\"]<1.5]\n",
    "df=df[df[\"269022\"]<4]\n",
    "df=df[df[\"269014\"]<15]\n",
    "df=df[df[\"269005\"]<3]\n",
    "df=df[df[\"155\"]<40]\n",
    "df=df[df[\"1345\"]<400]\n",
    "df=df[df[\"1127\"]<3000]\n",
    "df=df[df[\"34\"]<2]\n",
    "df=df[df[\"33\"]<10]\n",
    "df=df[df[\"317\"]>220]\n",
    "df=df[df[\"312\"]<20]\n",
    "df=df[df[\"2372\"]<20]\n",
    "df=df[df[\"2333\"]<10]\n",
    "df=df[df[\"10003\"]<60]\n",
    "df=df[df[\"10004\"]<500]\n",
    "df=df[df[\"1115\"]<300]\n",
    "df=df[df[\"10002\"]<40]\n",
    "df=df[df[\"1117\"]<400]\n",
    "df=df[df[\"1814\"]<400]\n",
    "df=df[df[\"1815\"]<200]\n",
    "df=df[(df[\"183\"]>50)&(df[\"183\"]<120)]\n",
    "df=df[df[\"1850\"]<40]\n",
    "df=df[df[\"190\"]<250]\n",
    "df=df[df[\"192\"]<100]\n",
    "df=df[df[\"193\"]<30]\n",
    "df=df[df[\"2174\"]>30]\n",
    "df=df[(df[\"2403\"]>20)&(df[\"2403\"]<10000)]\n",
    "df=df[df[\"2405\"]>10]\n",
    "df=df[df[\"300005\"]<100]\n",
    "df=df[df[\"3429\"]<100]\n",
    "df=df[df[\"3730\"]<10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37876, 435)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 绘制heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig=plt.figure(figsize=(12,10))\n",
    "# sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37876 9538 (37876, 5)\n"
     ]
    }
   ],
   "source": [
    "X_train=df.iloc[:,:-5]\n",
    "Y_train=df.iloc[:,-5:]\n",
    "\n",
    "all_data=pd.concat([X_train,X_test],axis=0)\n",
    "num_train=X_train.shape[0]\n",
    "num_test=X_test.shape[0]\n",
    "print(num_train,num_test,Y_train.shape)\n",
    "Y_train.to_csv(\"../datasets/tianchi/health/v9/Y_train_numeric_done-v9.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv(\"../datasets/tianchi/health/v9/all_data_outlier_done-v9.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##########################################################################\n",
    "####数值型数据处理完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=pd.read_csv(\"../datasets/tianchi/health/b_round/all_data_outlier_done-v9.csv\",low_memory=False)\n",
    "all_data=all_data.set_index(\"vid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理离散型数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用replace 及map函数处理离散变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"30007\"]=all_data[\"30007\"].replace({\"Ⅱ\":2,\"Ⅲ\":3,\"Ⅰ\":1,\"Ⅳ\":4,\"Ⅱ\":2,\"Ⅲ\":3,\"Ⅰ\":1,\"Ⅳ\":4,\"Ⅱ度\":2,\n",
    "                                            \"II\":2,\"Ⅲ度\":3,\"正常\":0,\"中度\":2,\"III\":3,\"ii°\":2,\"iii°\":3,\"Ⅰ°\":1,\n",
    "                                            \"Ⅱ°\":2,\"Ⅰ度\":1,\"Ⅳ度\":4,\"见TCT\":0,\"yellow\":0,\"-\":0,\"结果见TCT\":0,\n",
    "                                            \"Ⅳ°\":4,\"阴性\":0,\"微混\":0,\"Ⅲ°\":3,\"+\":2,\"I\":1,\"见刮片\":0,\"Ⅱv\":2,\n",
    "                                            \"Ⅰ Ⅰ\":1,np.nan:0,\"iv°\":4,\"i°\":1}).astype(\"float\")\n",
    "\n",
    "all_data[\"0431\"]=all_data[\"0431\"].replace({\"无\":\"正常\",\"无 无\":\"正常\",\"无压痛点\":\"正常\",\"未见异常 未见异常\":\"正常\",np.nan:\"未查\"})\n",
    "\n",
    "all_data[\"0976\"]=all_data[\"0976\"].replace({\"无\":\"正常\",\"无 无\":\"正常\",np.nan:\"未查\"})\n",
    "\n",
    "\n",
    "\n",
    "all_data[\"3400\"]=all_data[\"3400\"].map({\"透明\":\"透明\",\"浑浊\":\"浑浊\",\"混浊\":\"浑浊\",\"微混\":\"浑浊\"})\n",
    "all_data[\"3400\"].fillna(\"透明\",inplace=True)\n",
    "all_data[\"0215\"]=all_data[\"0215\"].map({np.nan:\"未查\",\"正常\":\"正常\"})\n",
    "all_data[\"0215\"]=all_data[\"0215\"].fillna(\"异常\")\n",
    "all_data[\"0216\"]=all_data[\"0216\"].map({np.nan:\"未查\",\"正常\":\"正常\",\"正常 正常\":\"正常\",\"未见异常 未见异常\":\"正常\"})\n",
    "all_data[\"0216\"]=all_data[\"0216\"].fillna(\"异常\")\n",
    "all_data[\"0217\"]=all_data[\"0217\"].map({np.nan:\"未查\",\"正常\":\"正常\",\"正常 正常\":\"正常\",\"未见异常 未见异常\":\"正常\"})\n",
    "all_data[\"0217\"]=all_data[\"0217\"].fillna(\"异常\")\n",
    "all_data[\"0405\"]=all_data[\"0405\"].map({np.nan:\"未查\",\"未闻及\":\"正常\",\"正常\":\"正常\",\"无\":\"正常\",\"未见异常 未见异常\":\"正常\"})\n",
    "all_data[\"0405\"]=all_data[\"0405\"].fillna(\"异常\")\n",
    "all_data[\"0406\"]=all_data[\"0406\"].map({np.nan:\"未查\",\"未触及 未触及\":\"正常\",\"正常\":\"正常\",\"未及\":\"正常\",\n",
    "                                       \"未见异常 未见异常\":\"正常\"})\n",
    "all_data[\"0406\"]=all_data[\"0406\"].fillna(\"异常\")\n",
    "all_data[\"0407\"]=all_data[\"0407\"].map({np.nan:\"未查\",\"未触及 未触及\":\"正常\",\"未及\":\"正常\",\"正常\":\"正常\",\n",
    "                                       \"未见异常 未见异常\":\"正常\",\"未触及\":\"正常\",\"不大\":\"正常\",})\n",
    "all_data[\"0407\"]=all_data[\"0407\"].fillna(\"异常\")\n",
    "all_data[\"0420\"]=all_data[\"0420\"].map({np.nan:\"未查\",\"未闻及异常\":\"正常\",\"正常 正常\":\"正常\",\"正常\":\"正常\",\n",
    "                                       \"未见异常 未见异常\":\"正常\",\"有力\":\"正常\",})\n",
    "all_data[\"0420\"]=all_data[\"0420\"].fillna(\"异常\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_data[\"0409\"]=all_data[\"0409\"]+all_data[\"0434\"]  ## 两次病史检查的数据合并处理，避免重复统计\n",
    "temp=[]\n",
    "all_data[\"0409\"]=all_data[\"0409\"].astype(\"str\")\n",
    "for i in range(len(all_data)):\n",
    "    if \"高血压\" in all_data[\"0409\"][i]:\n",
    "        temp.append(1)\n",
    "    elif \"血压偏高\" in all_data[\"0409\"][i]:\n",
    "        temp.append(1)\n",
    "    else:\n",
    "        temp.append(0)\n",
    "all_data[\"高血压史\"]=temp\n",
    "\n",
    "temp=[]\n",
    "for i in range(len(all_data)):\n",
    "    if \"高血脂\" in all_data[\"0409\"][i]:\n",
    "        temp.append(1)\n",
    "    elif \"血脂偏高\" in all_data[\"0409\"][i]:\n",
    "        temp.append(1)\n",
    "    else:\n",
    "        temp.append(0)\n",
    "all_data[\"高血脂史\"]=temp\n",
    "                        \n",
    "temp=[]\n",
    "for i in range(len(all_data)):\n",
    "    if \"糖尿病\" in all_data[\"0409\"][i]:\n",
    "        temp.append(1)\n",
    "    elif \"血糖偏高\" in all_data[\"0409\"][i]:\n",
    "        temp.append(1)\n",
    "    else:\n",
    "        temp.append(0)\n",
    "all_data[\"糖尿病史\"]=temp\n",
    "\n",
    "temp=[]\n",
    "for i in range(len(all_data)):\n",
    "    if \"冠心病\" in all_data[\"0409\"][i]:\n",
    "        temp.append(1)\n",
    "    else:\n",
    "        temp.append(0)\n",
    "all_data[\"冠心病史\"]=temp\n",
    "                        \n",
    "temp=[]\n",
    "for i in range(len(all_data)):\n",
    "    if \"肝\" in all_data[\"0409\"][i]:\n",
    "        temp.append(1)\n",
    "    else:\n",
    "        temp.append(0)\n",
    "all_data[\"肝病史\"]=temp\n",
    "\n",
    "                        \n",
    "temp=[]\n",
    "all_data[\"0439\"]=all_data[\"0439\"].astype(\"str\")\n",
    "for i in range(len(all_data)):\n",
    "    if \"冠心病\" in all_data[\"0439\"][i]:\n",
    "        temp.append(1)\n",
    "    else:\n",
    "        temp.append(0)\n",
    "all_data[\"父母冠心病\"]=temp\n",
    "                        \n",
    "temp=[]\n",
    "for i in range(len(all_data)):\n",
    "    if \"高血压\" in all_data[\"0439\"][i]:\n",
    "        temp.append(1)\n",
    "    else:\n",
    "        temp.append(0)\n",
    "all_data[\"父母高血压\"]=temp\n",
    "                        \n",
    "temp=[]\n",
    "for i in range(len(all_data)):\n",
    "    if \"糖尿病\" in all_data[\"0439\"][i]:\n",
    "        temp.append(1)\n",
    "    else:\n",
    "        temp.append(0)\n",
    "all_data[\"父母糖尿病\"]=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=[\"4001\"]\n",
    "for col in columns:\n",
    "    temp=[]\n",
    "    all_data[col]=all_data[col].astype(\"str\")\n",
    "    for i in range(len(all_data)):\n",
    "        if \"重度减弱\" in all_data[col][i]:\n",
    "            temp.append(3)\n",
    "        elif \"中度减弱\" in all_data[col][i]:\n",
    "            temp.append(2)\n",
    "        elif \"减弱\" in all_data[col][i]:\n",
    "            temp.append(1)\n",
    "        elif \"轻度硬化\" in all_data[col][i]:\n",
    "            temp.append(1)\n",
    "        elif \"硬化\" in all_data[col][i]:\n",
    "            temp.append(2)\n",
    "        elif \"钙化\" in all_data[col][i]:\n",
    "            temp.append(3)\n",
    "        else:\n",
    "            temp.append(0)\n",
    "    all_data[col]=temp\n",
    "\n",
    "columns=[\"0436\"]\n",
    "for col in columns:\n",
    "    temp=[]\n",
    "    all_data[col]=all_data[col].astype(\"str\")\n",
    "    for i in range(len(all_data)):\n",
    "        if \"无过敏\" in all_data[col][i]:\n",
    "            temp.append(\"正常\")\n",
    "        elif \"过敏史不详\" in all_data[col][i]:\n",
    "            temp.append(\"正常\")\n",
    "        elif \"过敏\" in all_data[col][i]:\n",
    "            temp.append(\"过敏\")\n",
    "        elif all_data[col][i]=='nan':\n",
    "            temp.append(\"未查\")\n",
    "        else:\n",
    "            temp.append(\"正常\")\n",
    "    all_data[col]=temp\n",
    "    \n",
    "columns=[\"1402\"]\n",
    "for col in columns:\n",
    "    temp=[]\n",
    "    all_data[col]=all_data[col].astype(\"str\")\n",
    "    for i in range(len(all_data)):\n",
    "        if \"增快\" in all_data[col][i]:\n",
    "            temp.append(\"增快\")\n",
    "        elif \"减慢\" in all_data[col][i]:\n",
    "            temp.append(\"减慢\")\n",
    "        elif \"弹性降低\" in all_data[col][i]:\n",
    "            temp.append(\"弹性降低\")\n",
    "        elif \"顺应性降低\" in all_data[col][i]:\n",
    "            temp.append(\"顺应性降低\")\n",
    "        elif all_data[col][i]=='nan':\n",
    "            temp.append(\"未查\")\n",
    "        else:\n",
    "            temp.append(\"正常\")\n",
    "    all_data[col]=temp\n",
    "\n",
    "    \n",
    "columns=[\"A705\"]\n",
    "for col in columns:\n",
    "    temp=[]\n",
    "    all_data[col]=all_data[col].astype(\"str\")\n",
    "    for i in range(len(all_data)):\n",
    "        if \"脂肪肝\" in all_data[col][i]:\n",
    "            temp.append(\"脂肪肝\")\n",
    "        elif \"脂肪含量超过正常值\" in all_data[col][i]:\n",
    "            temp.append(\"脂肪肝\")\n",
    "        elif \"硬度值偏高\" in all_data[col][i]:\n",
    "            temp.append(\"肝硬化\")\n",
    "        elif all_data[col][i]=='nan':\n",
    "            temp.append(\"未查\")\n",
    "        else:\n",
    "            temp.append(\"正常\")\n",
    "    all_data[col]=temp\n",
    "    \n",
    "    \n",
    "columns=[\"0987\"]\n",
    "for col in columns:\n",
    "    temp=[]\n",
    "    all_data[col]=all_data[col].astype(\"str\")\n",
    "    for i in range(len(all_data)):\n",
    "        if \"术后\" in all_data[col][i]:\n",
    "            temp.append(\"术后\")\n",
    "        elif all_data[col][i]=='nan':\n",
    "            temp.append(\"未查\")\n",
    "        else:\n",
    "            temp.append(\"正常\")\n",
    "    all_data[col]=temp\n",
    "    \n",
    "columns=[\"0984\"]\n",
    "for col in columns:\n",
    "    temp=[]\n",
    "    all_data[col]=all_data[col].astype(\"str\")\n",
    "    for i in range(len(all_data)):\n",
    "        if \"增生\" in all_data[col][i]:\n",
    "            temp.append(\"增生\")\n",
    "        elif all_data[col][i]=='nan':\n",
    "            temp.append(\"未查\")\n",
    "        else:\n",
    "            temp.append(\"正常\")\n",
    "    all_data[col]=temp\n",
    "    \n",
    "columns=[\"1308\",\"1316\",\"1330\"]\n",
    "for col in columns:\n",
    "    temp=[]\n",
    "    all_data[col]=all_data[col].astype(\"str\")\n",
    "    for i in range(len(all_data)):\n",
    "        if \"动脉硬化\" in all_data[col][i]:\n",
    "            temp.append(\"病变\")\n",
    "        elif \"黄斑\" in all_data[col][i]:\n",
    "            temp.append(\"病变\")\n",
    "        elif \"弧形斑\" in all_data[col][i]:\n",
    "            temp.append(\"病变\")\n",
    "        elif \"色素斑\" in all_data[col][i]:\n",
    "            temp.append(\"病变\")\n",
    "        elif \"病变\" in all_data[col][i]:\n",
    "            temp.append(\"病变\")\n",
    "        elif \"豹纹状眼底\" in all_data[col][i]:\n",
    "            temp.append(\"病变\")\n",
    "        elif \"结膜炎\" in all_data[col][i]:\n",
    "            temp.append(\"病变\")\n",
    "        elif all_data[col][i]=='nan':\n",
    "            temp.append(\"未查\")\n",
    "        else:\n",
    "            temp.append(\"正常\")\n",
    "    all_data[col]=temp\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "columns=[\"0113\",\"0114\",\"0115\",\"0117\",\"0118\",\"0120\",\"0121\",\"0122\",\"0123\",\"0124\"]\n",
    "for col in columns:\n",
    "    temp=[]\n",
    "    all_data[col]=all_data[col].astype(\"str\")\n",
    "    for i in range(len(all_data)):\n",
    "        if \"高回声\" in all_data[col][i]:\n",
    "            temp.append(\"高回声\")\n",
    "        elif \"强回声\" in all_data[col][i]:\n",
    "            temp.append(\"高回声\")\n",
    "        elif \"低回声\" in all_data[col][i]:\n",
    "            temp.append(\"低回声\")\n",
    "        elif \"弱回声\" in all_data[col][i]:\n",
    "            temp.append(\"低回声\")\n",
    "        elif \"无回声\" in all_data[col][i]:\n",
    "            temp.append(\"无回声\")\n",
    "        elif \"弥漫性\" in all_data[col][i]:\n",
    "            temp.append(\"弥漫性\")\n",
    "        elif \"欠清晰\" in all_data[col][i]:\n",
    "            temp.append(\"欠清晰\")\n",
    "        elif all_data[col][i]=='nan':\n",
    "            temp.append(\"未查\")\n",
    "        else:\n",
    "            temp.append(\"正常\")\n",
    "    all_data[col]=temp\n",
    "\n",
    "\n",
    "\n",
    "temp=[]\n",
    "all_data[\"0421\"]=all_data[\"0421\"].astype(\"str\")\n",
    "for i in range(len(all_data)):\n",
    "    if \"早搏\" in all_data[\"0421\"][i]:\n",
    "        temp.append(\"早搏\")\n",
    "    elif \"房颤\" in all_data[\"0421\"][i]:\n",
    "        temp.append(\"房颤\")\n",
    "    elif \"过速\" in all_data[\"0421\"][i]:\n",
    "        temp.append(\"过速\")\n",
    "    elif \"过缓\" in all_data[\"0421\"][i]:\n",
    "        temp.append(\"过缓\")\n",
    "    elif \"不齐\" in all_data[\"0421\"][i]:\n",
    "        temp.append(\"不齐\")\n",
    "    elif all_data[\"0421\"][i]=='nan':\n",
    "        temp.append(\"未查\")\n",
    "    else:\n",
    "        temp.append(\"正常\")\n",
    "all_data[\"0421\"]=temp\n",
    "\n",
    "temp=[]\n",
    "all_data[\"3601\"]=all_data[\"3601\"].astype(\"str\")\n",
    "for i in range(len(all_data)):\n",
    "    if \"严重骨质疏松\" in all_data[\"3601\"][i]:\n",
    "        temp.append(\"严重骨质疏松\")\n",
    "    elif \"疏松\" in all_data[\"3601\"][i]:\n",
    "        temp.append(\"疏松\")\n",
    "    elif \"减少\" in all_data[\"3601\"][i]:\n",
    "        temp.append(\"减少\")\n",
    "    elif \"降低\" in all_data[\"3601\"][i]:\n",
    "        temp.append(\"降低\")\n",
    "    elif all_data[\"3601\"][i]=='nan':\n",
    "        temp.append(\"未查\")\n",
    "    else:\n",
    "        temp.append(\"正常\")\n",
    "all_data[\"3601\"]=temp\n",
    "\n",
    "\n",
    "\n",
    "temp=[]\n",
    "all_data[\"0426\"]=all_data[\"0426\"].astype(\"str\")\n",
    "for i in range(len(all_data)):\n",
    "    if \"收缩期杂音\" in all_data[\"0426\"][i]:\n",
    "        temp.append(\"收缩期杂音\")\n",
    "    elif \"舒张期杂音\" in all_data[\"0426\"][i]:\n",
    "        temp.append(\"舒张期杂音\")\n",
    "    elif all_data[\"0426\"][i]=='nan':\n",
    "        temp.append(\"未查\")\n",
    "    else:\n",
    "        temp.append(\"正常\")\n",
    "all_data[\"0426\"]=temp\n",
    "\n",
    "temp=[]\n",
    "all_data[\"0435\"]=all_data[\"0435\"].astype(\"str\")\n",
    "for i in range(len(all_data)):\n",
    "    if \"腹部有压痛\" in all_data[\"0435\"][i]:\n",
    "        temp.append(\"腹部有压痛\")\n",
    "    elif all_data[\"0435\"][i]=='nan':\n",
    "        temp.append(\"未查\")\n",
    "    else:\n",
    "        temp.append(\"正常\")\n",
    "all_data[\"0435\"]=temp\n",
    "\n",
    "temp=[]\n",
    "all_data[\"0730\"]=all_data[\"0730\"].astype(\"str\")\n",
    "for i in range(len(all_data)):\n",
    "    if \"义齿\" in all_data[\"0730\"][i]:\n",
    "        temp.append(\"义齿\")\n",
    "    elif \"有\" in all_data[\"0730\"][i]:\n",
    "        temp.append(\"义齿\")\n",
    "    elif all_data[\"0730\"][i]=='nan':\n",
    "        temp.append(\"未查\")\n",
    "    else:\n",
    "        temp.append(\"正常\")\n",
    "all_data[\"0730\"]=temp\n",
    "\n",
    "temp=[]\n",
    "all_data[\"1328\"]=all_data[\"1328\"].astype(\"str\")\n",
    "for i in range(len(all_data)):\n",
    "    if \"色弱\" in all_data[\"1328\"][i]:\n",
    "        temp.append(\"色弱\")\n",
    "    elif \"色盲\" in all_data[\"1328\"][i]:\n",
    "        temp.append(\"色盲\")\n",
    "    elif all_data[\"1328\"][i]=='nan':\n",
    "        temp.append(\"未查\")\n",
    "    else:\n",
    "        temp.append(\"正常\")\n",
    "all_data[\"1328\"]=temp\n",
    "\n",
    "temp=[]\n",
    "all_data[\"0210\"]=all_data[\"0210\"].astype(\"str\")\n",
    "for i in range(len(all_data)):\n",
    "    if \"鼻炎\" in all_data[\"0210\"][i]:\n",
    "        temp.append(\"鼻炎\")\n",
    "    elif \"鼻窦炎\" in all_data[\"0210\"][i]:\n",
    "        temp.append(\"鼻窦炎\")\n",
    "    elif \"息肉\" in all_data[\"0210\"][i]:\n",
    "        temp.append(\"息肉\")\n",
    "    elif \"大\" in all_data[\"0210\"][i]:\n",
    "        temp.append(\"大\")\n",
    "    elif all_data[\"0210\"][i]=='nan':\n",
    "        temp.append(\"未查\")\n",
    "    else:\n",
    "        temp.append(\"正常\")\n",
    "all_data[\"0210\"]=temp\n",
    "\n",
    "temp=[]\n",
    "all_data[\"0423\"]=all_data[\"0423\"].astype(\"str\")\n",
    "for i in range(len(all_data)):\n",
    "    if \"粗\" in all_data[\"0423\"][i]:\n",
    "        temp.append(\"粗\")\n",
    "    elif \"弱\" in all_data[\"0423\"][i]:\n",
    "        temp.append(\"弱\")\n",
    "    elif \"消失\" in all_data[\"0423\"][i]:\n",
    "        temp.append(\"消失\")\n",
    "    elif all_data[\"0423\"][i]=='nan':\n",
    "        temp.append(\"未查\")\n",
    "    else:\n",
    "        temp.append(\"正常\")\n",
    "all_data[\"0423\"]=temp\n",
    "\n",
    "temp=[]\n",
    "all_data[\"0911\"]=all_data[\"0911\"].astype(\"str\")\n",
    "for i in range(len(all_data)):\n",
    "    if \"淋巴结肿大\" in all_data[\"0911\"][i]:\n",
    "        temp.append(\"淋巴结肿大\")\n",
    "    elif \"淋巴结大\" in all_data[\"0911\"][i]:\n",
    "        temp.append(\"淋巴结肿大\")\n",
    "    elif all_data[\"0911\"][i]=='nan':\n",
    "        temp.append(\"未查\")\n",
    "    else:\n",
    "        temp.append(\"正常\")\n",
    "all_data[\"0911\"]=temp\n",
    "\n",
    "temp=[]\n",
    "all_data[\"0912\"]=all_data[\"0912\"].astype(\"str\")\n",
    "for i in range(len(all_data)):\n",
    "    if \"不肿大\" in all_data[\"0912\"][i]:\n",
    "        temp.append(\"正常\")\n",
    "    elif \"无肿大\" in all_data[\"0912\"][i]:\n",
    "        temp.append(\"正常\")\n",
    "    elif \"结节\" in all_data[\"0912\"][i]:\n",
    "        temp.append(\"结节\")\n",
    "    elif \"肿大\" in all_data[\"0912\"][i]:\n",
    "        temp.append(\"肿大\")\n",
    "    elif \"欠光滑\" in all_data[\"0912\"][i]:\n",
    "        temp.append(\"欠光滑\")\n",
    "    elif all_data[\"0912\"][i]=='nan':\n",
    "        temp.append(\"未查\")\n",
    "    else:\n",
    "        temp.append(\"正常\")\n",
    "all_data[\"0912\"]=temp\n",
    "\n",
    "\n",
    "temp=[]\n",
    "all_data[\"0973\"]=all_data[\"0973\"].astype(\"str\")\n",
    "for i in range(len(all_data)):\n",
    "    if \"已手术\" in all_data[\"0973\"][i]:\n",
    "        temp.append(\"已手术\")\n",
    "    elif \"疝\" in all_data[\"0973\"][i]:\n",
    "        temp.append(\"疝\")\n",
    "    elif all_data[\"0973\"][i]=='nan':\n",
    "        temp.append(\"未查\")\n",
    "    else:\n",
    "        temp.append(\"正常\")\n",
    "all_data[\"0973\"]=temp\n",
    "\n",
    "temp=[]\n",
    "all_data[\"0974\"]=all_data[\"0974\"].astype(\"str\")\n",
    "for i in range(len(all_data)):\n",
    "    if \"皮炎\" in all_data[\"0974\"][i]:\n",
    "        temp.append(\"皮炎\")\n",
    "    elif \"癣\" in all_data[\"0974\"][i]:\n",
    "        temp.append(\"癣\")\n",
    "    elif \"疹\" in all_data[\"0974\"][i]:\n",
    "        temp.append(\"疹\")\n",
    "    elif \"银屑病\" in all_data[\"0974\"][i]:\n",
    "        temp.append(\"银屑病\")\n",
    "    elif \"白癜风\" in all_data[\"0974\"][i]:\n",
    "        temp.append(\"白癜风\")\n",
    "    else:\n",
    "        temp.append(\"正常\")\n",
    "all_data[\"0974\"]=temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [03:31<00:00,  9.60s/it]\n"
     ]
    }
   ],
   "source": [
    "columns=[\"100010\",\"3190\",\"3191\",\"3192\",\"3195\",\"3196\",\"3197\",\"3207\",\"3430\",\"2228\",\"2229\",\"2230\",\n",
    "        \"2233\",\"2231\",\"360\",\"3301\",\"3189\",\"3194\",\"3485\",\"3486\",\"2282\",\"30002\"]\n",
    "for col in tqdm(columns):\n",
    "    temp=[]\n",
    "    all_data[col]=all_data[col].astype(\"str\")\n",
    "    for i in range(len(all_data)):\n",
    "        if \"++++\" in all_data[col][i]:\n",
    "            temp.append(4)\n",
    "        elif \"+++\" in all_data[col][i]:\n",
    "            temp.append(3)\n",
    "        elif \"++\" in all_data[col][i]:\n",
    "            temp.append(2)\n",
    "        elif \"+-\" in all_data[col][i]:\n",
    "            temp.append(0.5)\n",
    "        elif \"+\" in all_data[col][i]:\n",
    "            temp.append(1)\n",
    "        elif \"阳性\" in all_data[col][i]:\n",
    "            temp.append(1)\n",
    "        elif all_data[col][i]==\"nan\":\n",
    "            temp.append(np.nan)\n",
    "        else:\n",
    "            temp.append(0)\n",
    "    all_data[col]=temp\n",
    "    all_data[col]=all_data[col].fillna(all_data[col].mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=[\"2302\"]\n",
    "for col in columns:\n",
    "    all_data[col]=all_data[col].replace({\"正常\":\"健康\"})\n",
    "    temp=[]\n",
    "    for i in range(len(all_data)):\n",
    "        \n",
    "        pattern = re.compile(r'[\\u4e00-\\u9fa5]+')\n",
    "        try:\n",
    "            temp.append(pattern.findall(all_data[col][i])[0])\n",
    "        except:\n",
    "            temp.append(np.nan)\n",
    "    all_data[col]=temp\n",
    "    all_data[col]=all_data[col].fillna(\"未查\")\n",
    "    all_data[col]=all_data[col].replace({\"肥健康\":\"健康\",\"正常疲劳反应\":\"健康\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 删除结构过于单一和无用features\n",
    "all_data.drop([\"1102\",\"0116\",\"0119\",\"0201\",\"0202\",\"0731\",\"0732\",\"300131\",\"3731\",\"0409\",\"0434\",\"0439\",\n",
    "               \"0203\",\"0206\",\"0207\",\"0208\",\"0209\",\"0222\",\"0403\",\"0413\",\"0429\",\"0715\",\"0726\",\"0728\",\"0702\",\n",
    "               \"0501\",\"0503\",\"0509\",\"0516\",\"0537\",\"0539\",\"0541\",\"0703\",\"0705\",\"0706\",\"0707\",\"0709\",\"3813\",\n",
    "               \"0901\",\"0947\",\"0949\",\"0954\",\"0972\",\"0975\",\"0977\",\"0978\",\"0979\",\"0980\",\"0985\",\"1001\",\n",
    "               \"1103\",\"1301\",\"1302\",\"1303\",\"1304\",\"1305\",\"1313\",\"1314\",\"1315\",\"3399\",\"A201\",\"A202\",\n",
    "               \"0212\",\"0430\",\"0432\",\"0433\",\"0976\",\"0422\",\"0427\",\"1329\",\"2501\",\"979027\",\"0986\",\"1104\",\n",
    "               \"A601\",\"0225\",\"0414\",\"0415\",\"0428\",\"0440\",\"0546\",\"0981\",\"0982\",\"0983\",\"0213\",\"0929\",\n",
    "              \"A301\",\"A302\",\"3101\",\"0218\",\"1335\",\"3725\",\"3738\",\"1337\",\"1002\",\"0224\",\"0441\",\"0220\",\n",
    "              \"439032\"],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data.to_csv(\"../datasets/tianchi/health/v9/all_data_pivot_all_done-v94.csv\") #### 除去0101,0102全部处理完成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检查是否仍有缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data=pd.read_csv(\"../datasets/tianchi/health/v9/all_data_pivot_all_done-v94.csv\",low_memory=False)\n",
    "# all_data.set_index(\"vid\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.drop([\"0101\",\"0102\",\"num_items\"],axis=1,inplace=True)  ###0101检查项目0102中都有，因此drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## box cox sknewed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skew in numerical features: \n",
      "\n",
      "There are 247 skewed numerical features to Box Cox transform\n"
     ]
    }
   ],
   "source": [
    "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "# Check the skew of all numerical features\n",
    "skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "print(\"\\nSkew in numerical features: \\n\")\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "\n",
    "skewness = skewness[abs(skewness.Skew) > 0.75]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    all_data[feat] = boxcox1p(all_data[feat], lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getdummy之后生成最终数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=pd.get_dummies(all_data,drop_first=True)\n",
    "\n",
    "X_train=all_data.iloc[:-m_test,:]\n",
    "X_test=all_data.iloc[-m_test:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 由于目标函数是log1p的平方差，所以我们对y进行log1p转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=pd.read_csv(\"../datasets/tianchi/health/b_round/Y_train_numeric_done-v9.csv\")\n",
    "Y_train.set_index(\"vid\",inplace=True)\n",
    "Y_train=np.log(Y_train+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37877, 430) (9532, 430)\n"
     ]
    }
   ],
   "source": [
    "assert np.sum(X_train.index!=Y_train.index)==0\n",
    "assert np.sum(X_test.index!=Y_pred.index)==0\n",
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立模型 交叉验证性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso, BayesianRidge, LassoLarsIC,LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor,ExtraTreesRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds=5\n",
    "def rmse_cv(model,i):\n",
    "    mse= -cross_val_score(model, X_train.values, Y_train.values[:,i], \n",
    "                                   scoring=\"neg_mean_squared_error\", cv = n_folds)\n",
    "    return(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_lasso=make_pipeline(RobustScaler(), Lasso(alpha =0.00015, random_state=1,max_iter=10000))\n",
    "# for i in range(5):\n",
    "#     scores=rmse_cv(reg_lasso,i)\n",
    "#     print(\"lasso scores {:.4f}(with std: {:.4f})\".format(scores.mean(),scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg_ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0015, l1_ratio=.1, max_iter=10000,random_state=3))\n",
    "# for i in range(5):\n",
    "#     scores=rmse_cv(reg_ENet,i)\n",
    "#     print(\"ENet scores {:.4f}(with std: {:.4f})\".format(scores.mean(),scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=20,   \n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,n_jobs=4,\n",
    "                              min_data_in_leaf =16, min_sum_hessian_in_leaf = 11)\n",
    "# for i in range(3,4):\n",
    "#     scores=rmse_cv(reg_lgb,i)\n",
    "#     print(\"Lightgbm scores {:.5f}(with std: {:.5f})\".format(scores.mean(),scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lightgbm scores 0.01278"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_GDBT = GradientBoostingRegressor(n_estimators=1174, learning_rate=0.015,\n",
    "                                   max_depth=9, max_features='sqrt',\n",
    "                                   min_samples_leaf=46, min_samples_split=8,\n",
    "                                   loss='huber', random_state =10) \n",
    "# for i in range(3,4):\n",
    "#     scores=rmse_cv(reg_GDBT,i)\n",
    "#     print(\"GDBT scores {:.5f}(with std: {:.5f})\".format(scores.mean(),scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GDBT scores 0.0142(with std: 0.0004)  \n",
    "GDBT scores 0.0182(with std: 0.0005)  \n",
    "GDBT scores 0.0736(with std: 0.0024)  \n",
    "GDBT scores 0.0131(with std: 0.0014)  \n",
    "GDBT scores 0.0369(with std: 0.0023)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看feature importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_importance(model):   \n",
    "    \n",
    "#     columns=[\"Systolic\",\"Diastolic\",\"Glycerin\",\"HDC\",\"LDC\"]\n",
    "#     importance=pd.DataFrame()\n",
    "#     for col in columns:\n",
    "#         model.fit(X_train.values,Y_train[col])\n",
    "#         importance[\"feature\"]=X_train.columns.values\n",
    "#         importance[\"importance_\"+col]=model.feature_importances_\n",
    "#     importance=importance.set_index(\"feature\")\n",
    "    \n",
    "#     return importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importance=get_importance(reg_GDBT)\n",
    "#importance.to_csv(\"../datasets/tianchi/health/importance of GDBT-97%.csv\",)\n",
    "#importance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_xgb = xgb.XGBRegressor(colsample_bytree=0.7184, \n",
    "                           gamma=0.1253,n_estimators=740,n_jobs=4,\n",
    "                             learning_rate=0.02, max_depth=8,\n",
    "                             min_child_weight=16.154, reg_alpha=0.2695,\n",
    "                             subsample=0.8171, silent=1,reg_lambda=0.1855,\n",
    "                             )\n",
    "# for i in range(5):\n",
    "#     scores=rmse_cv(reg_xgb,i)\n",
    "#     print(\"XGBoost scores {:.4f}(with std: {:.4f})\".format(scores.mean(),scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGboost scores 0.0142(with std: 0.0004)  \n",
    "XGboost scores 0.0183(with std: 0.0005)  \n",
    "XGboost scores 0.0728(with std: 0.0025)  \n",
    "XGboost scores 0.0131(with std: 0.0013)  \n",
    "XGboost scores 0.0365(with std: 0.0025)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_et=ExtraTreesRegressor(n_estimators=354,max_features=0.3,          \n",
    "                           max_depth=68,n_jobs=-1,min_samples_split=2,\n",
    "                             min_samples_leaf=6,random_state=42)\n",
    "# for i in range(5):\n",
    "#     scores=rmse_cv(reg_et,i)\n",
    "#     print(\"ExtraTrees scores {:.4f}(with std: {:.4f})\".format(scores.mean(),scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Averaged Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([model.predict(X) for model in self.models_])\n",
    "        \n",
    "        return np.mean(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# averaged_models = AveragingModels(models = (reg_GDBT,reg_lgb,reg_xgb))\n",
    "\n",
    "# for i in range(3,4):\n",
    "#     scores=rmse_cv(averaged_models,i)\n",
    "#     print(\"AveragingModels scores {:.5f}(with std: {:.5f})\".format(scores.mean(),scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try Stacking by Stacknet which is coded by java ！ faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        \n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                \n",
    "                self.base_models_[i].append(instance)\n",
    "\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                \n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1) for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg_lasso_stack=make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1,max_iter=10000))\n",
    "\n",
    "stacked_averaged_models = StackingAveragedModels(base_models = (reg_lgb,reg_GDBT,reg_lasso,reg_ENet,reg_et,reg_xgb),\n",
    "                                                 meta_model = reg_lasso_stack )\n",
    "# for i in range(3,4):\n",
    "#     scores=rmse_cv(stacked_averaged_models,i)\n",
    "#     print(\"stacked_averaged_models scores {:.5f}(with std: {:.5f})\".format(scores.mean(),scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stacked_averaged_models scores 0.0141(with std: 0.0004)  \n",
    "stacked_averaged_models scores 0.0181(with std: 0.0005)  \n",
    "stacked_averaged_models scores 0.0723(with std: 0.0026)  \n",
    "stacked_averaged_models scores 0.0129(with std: 0.0014)  \n",
    "stacked_averaged_models scores 0.0365(with std: 0.0027)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目前看stacked 和XGB 效果较好\n",
    "我们直接fit X_train 得出预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_averaged_models.fit(X_train.values,Y_train.values[:,3])\n",
    "y4_stacked=stacked_averaged_models.predict(X_test.values)\n",
    "print(\"y4 done!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建X_train_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub=pd.read_csv('../datasets/tianchi/health/b_round/meinian_round1_test_b_20180505.csv',\n",
    "                       engine='python',encoding=\"gbk\")\n",
    "df_sub[\"血清高密度脂蛋白\"]=np.exp(y4_stacked)-1\n",
    "\n",
    "df_sub.to_csv('../datasets/tianchi/health/b_round/4_stacked_xgb.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
